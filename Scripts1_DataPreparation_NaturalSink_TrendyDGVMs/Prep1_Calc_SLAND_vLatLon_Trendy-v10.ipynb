{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import cftime\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time as t_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9db7d",
   "metadata": {},
   "source": [
    "## Define experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'S3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_trendy    = '/Trendy/Data/'\n",
    "dir_data_orig = '/Trendy/Data/Trendy-v10_' + experiment + '/'\n",
    "dir_data_corr = '/Trendy/Data/Trendy-v10_' + experiment + '_corr/'\n",
    "dir_countries = '/Trendy/Data/data_ancillary/info_countries/'\n",
    "dir_forest    = '/GCB2021_commentary/Data/forest_masks/'\n",
    "dir_LSMs      = '/Trendy/Data/LSMs_Trendy-v10/LSMs_unified/'\n",
    "dir_LSMs_out  = '/Trendy/Data/LSMs_Trendy-v10/'\n",
    "dir_tmp       = '/Trendy/Data/tmp/'\n",
    "dir_grids     = '/Trendy/Data/grids/'\n",
    "dir_out       = '/Trendy/Data/SLAND_Trendy-v10_' + experiment + '_LatLon/'\n",
    "if not os.path.exists(dir_out):  os.mkdir(dir_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f68526",
   "metadata": {},
   "source": [
    "## Create reference grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab87431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select reference grid\n",
    "sel_ref = 'CountryMask'\n",
    "# sel_ref = 'LPJ-GUESS'\n",
    "sel_ref = 'ForestMask'\n",
    "\n",
    "#Select input files\n",
    "if sel_ref=='CountryMask':\n",
    "    fname_in = dir_countries + 'wrld_cntrs_BLUE_TN_upd.nc'\n",
    "    variab   = 'ISOcode'\n",
    "    annex    = ''\n",
    "elif sel_ref=='ForestMask':\n",
    "    fname_in = dir_forest + 'Hansen2010_IFL_2013.nc'\n",
    "    variab   = 'Band1'\n",
    "    annex    = '-ForestMask'\n",
    "elif sel_ref=='LPJ-GUESS':\n",
    "    fname_in = dir_data_orig + 'LPJ-GUESS/LPJ-GUESS_S2_nbp.nc'\n",
    "    variab   = 'nbp'\n",
    "    annex    = ''    \n",
    "\n",
    "#Get size of lat and lon\n",
    "dat_ref = xr.open_dataset(fname_in)\n",
    "if 'latitude' in dat_ref.dims:  lat_name, lon_name = 'latitude', 'longitude'\n",
    "else:                           lat_name, lon_name = 'lat', 'lon'    \n",
    "\n",
    "#File name for grid description\n",
    "grid_size = str(len(dat_ref[lat_name])) + 'x' + str(len(dat_ref[lon_name]))\n",
    "fname_grid = dir_grids + 'grid_xy_' + grid_size + annex\n",
    "\n",
    "#Create reference grid\n",
    "if os.path.exists(fname_grid): os.remove(fname_grid)\n",
    "os.system('cdo -s griddes -selvar,' + variab + ' ' + fname_in + ' > ' + fname_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb3904",
   "metadata": {},
   "source": [
    "## Prepare land-sea mask for plotting maps (remap to fit correct grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define grid resolution for remapping\n",
    "resolution = '360x720'#'720x1440'#'360x720-ForestMask'#\n",
    "\n",
    "#Define file names\n",
    "file_grid    = dir_grids + 'grid_xy_' + resolution\n",
    "fname_LSM    = dir_LSMs + 'LandFrac_DLEM.nc'\n",
    "fname_remap  = dir_LSMs + 'LandFrac_DLEM_remap.nc'\n",
    "fname_LSMout = dir_LSMs_out + 'LandSeaMask_' + resolution + '.nc'\n",
    "if os.path.exists(fname_remap):   os.remove(fname_remap)\n",
    "if os.path.exists(fname_LSMout):  os.remove(fname_LSMout)\n",
    "    \n",
    "#Remap\n",
    "os.system('cdo remapbil,' + file_grid + ' ' + fname_LSM + ' ' + fname_remap)\n",
    "\n",
    "#Open and convert to land-sea mak\n",
    "data_LSM = xr.open_dataset(fname_remap)\n",
    "data_LSM = 1 * (data_LSM.LandFrac>0)\n",
    "data_LSM = data_LSM.to_dataset(name='sftlf')\n",
    "\n",
    "#Save in NetCDF\n",
    "data_LSM.to_netcdf(fname_LSMout)\n",
    "\n",
    "#Delete temporary file\n",
    "os.remove(fname_remap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a4af7",
   "metadata": {},
   "source": [
    "## Calculate yearly SLAND from NBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9171c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [#'CABLE-POP', 'CLASSIC', 'CLASSIC-N', 'CLM5.0', 'DLEM', 'IBIS', 'ISAM', \n",
    "          'ISBA-CTRIP', \n",
    "          'JSBACH', 'JULES-ES-1.1', 'LPJ-GUESS', 'LPJwsl', 'LPX-Bern', 'OCN', 'ORCHIDEE', 'ORCHIDEEv3', 'SDGVM', 'VISIT', 'YIBs']\n",
    "\n",
    "resolutions = ['360x720', '720x1440']#, '360x720-ForestMask']\n",
    "\n",
    "#Define compression level\n",
    "comp = dict(zlib=True, complevel=2)\n",
    "\n",
    "#Loop over models\n",
    "for model in models:\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    #Define folder and get file name\n",
    "    dir_model_orig = dir_data_orig + model + '/'\n",
    "    dir_model_corr = dir_data_corr + model + '/'\n",
    "    files_nbp_orig = [dir_model_orig + file for file in os.listdir(dir_model_orig) if '_nbp' in file and 'nbppft' not in file and experiment + '_' in file]\n",
    "    \n",
    "    #Check if corrected file exists\n",
    "    if os.path.exists(dir_model_corr):\n",
    "        files_nbp_corr = [dir_model_corr + file for file in os.listdir(dir_model_corr) if '_nbp' in file and 'nbppft' not in file and experiment + '_' in file]\n",
    "        N = len(files_nbp_corr)\n",
    "    else:\n",
    "        N = 0\n",
    "        \n",
    "    #Select file name\n",
    "    if N>0:  files_nbp = files_nbp_corr\n",
    "    else:    files_nbp = files_nbp_orig\n",
    "        \n",
    "    #Check if file is unique\n",
    "    if len(files_nbp)!=1:\n",
    "        sys.exit('Filename not unique')\n",
    "    else:\n",
    "        file_nbp = files_nbp[0]\n",
    "    \n",
    "    #Define variable name for time\n",
    "    if model in ['ISBA-CTRIP', 'ORCHIDEEv3']:\n",
    "        time_var = 'time_counter'\n",
    "    else:\n",
    "        time_var = 'time'\n",
    "\n",
    "    #Read data and check if it is monthly or yearly\n",
    "    data_nbp = xr.open_dataset(file_nbp, use_cftime=True)\n",
    "    if np.mean(np.diff(data_nbp[time_var]))>datetime.timedelta(days=180):\n",
    "        sel = 'year'\n",
    "    else:\n",
    "        sel = 'month'        \n",
    "    \n",
    "    #Define file names\n",
    "    fname_Ysum_tmp  = dir_tmp + model + '_NBP_latlon_yearsum_tmp.nc'\n",
    "    fname_Ysum      = dir_tmp + model + '_NBP_latlon_yearsum.nc'\n",
    "    fname_area      = dir_tmp + model + '_NBP_latlon_gridarea.nc'\n",
    "    fname_area_reg  = dir_tmp + model + '_NBP_latlon_gridarea_regrid.nc'\n",
    "    fname_flux      = dir_tmp + model + '_NBP_latlon_flux_tmp.nc'\n",
    "    fname_SLden     = dir_tmp + model + '_' + experiment + '_SLANDdensity_NBP.nc'  \n",
    "    fname_SLAND     = dir_out + model + '_' + experiment + '_SLAND_NBP.nc'  \n",
    "    if os.path.exists(fname_SLAND):      os.remove(fname_SLAND)\n",
    "        \n",
    "    #Calculate yearly values and save in new file\n",
    "    if model=='VISIT':\n",
    "        \n",
    "        #Open dataset\n",
    "        data_VISIT = xr.open_dataset(file_nbp)\n",
    "\n",
    "        #Calculate yearly values and remove temporary file\n",
    "        if sel=='year':\n",
    "            N_days = 365 + data_VISIT.time.dt.is_leap_year\n",
    "            data_VISIT = data_VISIT * 86400 * N_days\n",
    "        elif sel=='month':\n",
    "            N_days = data_VISIT.time.dt.days_in_month\n",
    "            data_VISIT = data_VISIT * 86400 * N_days\n",
    "        \n",
    "        data_VISIT = data_VISIT.resample(time='1Y').sum('time')\n",
    "        data_VISIT.to_netcdf(fname_Ysum_tmp)\n",
    "\n",
    "    else:\n",
    "        if sel=='year':\n",
    "            os.system(\"cdo -muldpy -mulc,86400 \" + file_nbp + \" \" + fname_Ysum_tmp)\n",
    "        elif sel=='month':\n",
    "            os.system(\"cdo -yearsum -muldpm -mulc,86400 \" + file_nbp + \" \" + fname_Ysum_tmp)\n",
    "    \n",
    "    #Read data\n",
    "    data = xr.open_dataset(fname_Ysum_tmp, engine='netcdf4')\n",
    "\n",
    "    #Rename variable for SDGVM\n",
    "    if 'nbp_annual' in data.data_vars:  data = data.rename({'nbp_annual': 'nbp'})\n",
    "        \n",
    "    #Remove data variables that are not necessary\n",
    "    vars_del = [var for var in data.data_vars if var!='nbp']\n",
    "    data = data.drop(vars_del)\n",
    "    data = data.fillna(0)\n",
    "    data.to_netcdf(fname_Ysum)\n",
    "    \n",
    "    #Get grid area\n",
    "    os.system('cdo gridarea ' + fname_Ysum + ' ' + fname_area)\n",
    "        \n",
    "    #Multiply land fraction for models for which it is necessary\n",
    "    files_LSM = [file for file in os.listdir(dir_LSMs) if (model + '.nc' in file) and ('CellArea' not in file)]\n",
    "    if model in ['CLM5.0', 'DLEM', 'IBIS', 'ISBA-CTRIP',  'JULES-ES-1.1', 'OCN', 'ORCHIDEEv3']:\n",
    "        print(\"  -Include land fraction: \" + files_LSM[0])\n",
    "        fname_LandFrac     = dir_LSMs + files_LSM[0]\n",
    "        fname_multiply     = dir_tmp + model + '_NBP_GCB2021_gridarea_corrected.nc'\n",
    "        os.system('cdo -mul ' + fname_area + ' ' + fname_LandFrac + ' ' + fname_multiply)\n",
    "        del_multiply = True\n",
    "    else:\n",
    "        fname_multiply = fname_area\n",
    "        del_multiply = False\n",
    "\n",
    "    #Calculate flux and convert to Pg C\n",
    "    os.system('cdo -mulc,1e-12 -mul ' + fname_Ysum + ' ' + fname_multiply + ' ' + fname_flux)\n",
    "    os.system('cdo -z zip_2 setname,SLAND ' + fname_flux + ' ' + fname_SLAND)\n",
    "    \n",
    "    #Calculate SLAND density\n",
    "    os.system('cdo div ' + fname_SLAND + ' ' + fname_area + ' ' + fname_SLden)    \n",
    "    \n",
    "    #Loop over different resolutions\n",
    "    fnames_rename = [fname_SLAND]\n",
    "    for resolution in resolutions:\n",
    "        \n",
    "        #Define output file names\n",
    "        fname_SLden_reg = dir_tmp + model + '_' + experiment + '_SLANDdensity_NBP_regrid' + resolution + '.nc'\n",
    "        fname_SLAND_reg = dir_out + model + '_' + experiment + '_SLAND_NBP_regrid' + resolution + '.nc'  \n",
    "        if os.path.exists(fname_SLAND_reg):  os.remove(fname_SLAND_reg)\n",
    "        \n",
    "        #Remap data to common grid\n",
    "        file_grid = dir_grids + 'grid_xy_' + resolution    \n",
    "\n",
    "        #Regrid corrected NBP\n",
    "        os.system('cdo remapcon,' + file_grid + ' ' + fname_SLden + ' ' + fname_SLden_reg)\n",
    "\n",
    "        #Get cell area of regridded file and calculate regridded SLAND\n",
    "        os.system('cdo gridarea ' + fname_SLden_reg + ' ' + fname_area_reg)\n",
    "        os.system('cdo -z zip_2 mul ' + fname_SLden_reg + ' ' + fname_area_reg + ' ' + fname_SLAND_reg)\n",
    "\n",
    "        #Collect file names for renaming\n",
    "        fnames_rename.append(fname_SLAND_reg)\n",
    "        \n",
    "        #Remove temporary files\n",
    "        os.remove(fname_area_reg)\n",
    "        os.remove(fname_SLden_reg)\n",
    "    \n",
    "    #Remove temporary files\n",
    "    os.remove(fname_Ysum_tmp)\n",
    "    os.remove(fname_Ysum)\n",
    "    os.remove(fname_area)\n",
    "    os.remove(fname_flux)\n",
    "    os.remove(fname_SLden)\n",
    "    if del_multiply==True:\n",
    "        os.remove(fname_multiply)\n",
    "        \n",
    "    #Rename time_counter to time for ISBA-CTRIP and ORCHIDEEv3\n",
    "    if model in ['ISBA-CTRIP', 'ORCHIDEEv3']:\n",
    "        for fname in fnames_rename:\n",
    "            fname2 = fname[0:-3] + '_tmp.nc'\n",
    "            data_corr = xr.open_dataset(fname)\n",
    "            data_corr = data_corr.rename({'time_counter': 'time'})\n",
    "            encoding = {var: comp for var in data_corr.data_vars}\n",
    "            data_corr.to_netcdf(fname2, encoding=encoding)\n",
    "            os.remove(fname)\n",
    "            os.rename(fname2, fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9a903-998f-4cee-87fe-6dd79592f99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
