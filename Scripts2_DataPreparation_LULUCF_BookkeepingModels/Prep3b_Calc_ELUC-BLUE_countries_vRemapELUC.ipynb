{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ELUC  = '/GCB2021/Data/Output_GCB2021/202109_GCB2021_run/run_v1_1700-2021/'\n",
    "dir_ctrs  = '/Trendy/Data/data_ancillary/info_countries/'\n",
    "dir_grids = '/Trendy/Data/grids/'\n",
    "dir_out   = '/GCB2021_commentary/Data/ELUC_countries/'\n",
    "dir_tmp   = '/Trendy/Data/tmp/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BLUE grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create reference grid\n",
    "fname_in = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD.nc'\n",
    "fname_grid = dir_out + 'grid_xy_BLUE'\n",
    "os.system('cdo griddes -selvar,CD_A' + ' ' + fname_in + ' > ' + fname_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ELUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Read ELUC data\n",
    "# fname = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD.nc'\n",
    "# data_read = xr.open_dataset(fname)\n",
    "\n",
    "# #Select time\n",
    "# time_sta = '2000'\n",
    "# time_end = '2020'\n",
    "\n",
    "# #Select time period and variable\n",
    "# data_read = data_read.sel(time=slice(time_sta, None))\n",
    "# data_ELUC = data_read['CD_A']\n",
    "\n",
    "# #Calculate ELUC\n",
    "# data_ELUC = data_ELUC.diff('time')\n",
    "# data_ELUC['time'] = data_ELUC['time'] - 1\n",
    "# data_ELUC = data_ELUC.sel(time=slice(time_sta, time_end))\n",
    "\n",
    "# #Convert from tC/ha to Tg C\n",
    "# data_ELUC = data_ELUC * data_read.cell_area / 1e6\n",
    "# data_ELUC = data_ELUC.to_dataset(name='ELUC')\n",
    "# data_ELUC.ELUC.attrs['unit'] = 'Tg C/year'\n",
    "\n",
    "# #Define compression level\n",
    "# comp = dict(zlib=True, complevel=2)\n",
    "# encoding = {var: comp for var in data_ELUC.data_vars}\n",
    "\n",
    "# #Save in file\n",
    "# fname_out = dir_out + 'ELUC_BLUE_GCB2021_' + time_sta + '-' + time_end + '.nc'\n",
    "# data_ELUC.to_netcdf(fname_out, encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select time\n",
    "time_sta = '2000'\n",
    "time_end = '2020'\n",
    "\n",
    "#Define necessary variables\n",
    "variables = ['CD_A', 'CD_A_c', 'CD_A_p', 'CD_A_dec_h', 'CD_A_deg_d', 'CD_A_a', 'CD_A_reg_h', 'CD_A_deg_rec_d', 'cell_area']\n",
    "\n",
    "#Read data\n",
    "file_2021_HIS = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD_PerHistoryType.nc'\n",
    "file_2021_COV = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD_PerCoverType.nc'\n",
    "file_2021_SUM = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD.nc'\n",
    "data_2021_HIS = xr.open_dataset(file_2021_HIS)\n",
    "data_2021_COV = xr.open_dataset(file_2021_COV)\n",
    "data_2021_SUM = xr.open_dataset(file_2021_SUM)\n",
    "\n",
    "#Select in time period\n",
    "data_2021_HIS = data_2021_HIS.sel(time=slice(time_sta, None))\n",
    "data_2021_COV = data_2021_COV.sel(time=slice(time_sta, None))\n",
    "data_2021_SUM = data_2021_SUM.sel(time=slice(time_sta, None))\n",
    "\n",
    "#Select variables to extract for PerHistoryType file\n",
    "variables_drop_HIS = [variab for variab in data_2021_HIS.data_vars if variab not in variables]\n",
    "variables_drop_COV = [variab for variab in data_2021_COV.data_vars if variab not in variables]\n",
    "variables_drop_SUM = [variab for variab in data_2021_SUM.data_vars if variab not in variables]\n",
    "\n",
    "data_2021_HIS = data_2021_HIS.drop(variables_drop_HIS)\n",
    "data_2021_COV = data_2021_COV.drop(variables_drop_COV)\n",
    "data_2021_SUM = data_2021_SUM.drop(variables_drop_SUM)\n",
    "\n",
    "data_sources = data_2021_COV['CD_A_c'] + data_2021_COV['CD_A_p'] + data_2021_HIS['CD_A_dec_h'] + data_2021_HIS['CD_A_deg_d']\n",
    "data_sinks   = data_2021_HIS['CD_A_a'] + data_2021_HIS['CD_A_reg_h'] + data_2021_HIS['CD_A_deg_rec_d']\n",
    "data_net     = data_2021_SUM['CD_A']\n",
    "\n",
    "#Calculate ELUC\n",
    "BLUE_ELUC_sources = data_sources.diff('time')\n",
    "BLUE_ELUC_sinks   = data_sinks.diff('time')\n",
    "BLUE_ELUC_net     = data_net.diff('time')\n",
    "BLUE_ELUC_sources['time'] = BLUE_ELUC_sources['time'] - 1\n",
    "BLUE_ELUC_sinks['time']   = BLUE_ELUC_sinks['time'] - 1\n",
    "BLUE_ELUC_net['time']     = BLUE_ELUC_net['time'] - 1\n",
    "BLUE_ELUC_sources = BLUE_ELUC_sources.sel(time=slice(time_sta, time_end))\n",
    "BLUE_ELUC_sinks   = BLUE_ELUC_sinks.sel(time=slice(time_sta, time_end))\n",
    "BLUE_ELUC_net     = BLUE_ELUC_net.sel(time=slice(time_sta, time_end))\n",
    "\n",
    "#Convert from tC/ha to Tg C\n",
    "BLUE_ELUC_sources = BLUE_ELUC_sources * data_2021_SUM.cell_area / 1e6\n",
    "BLUE_ELUC_sinks   = BLUE_ELUC_sinks * data_2021_SUM.cell_area / 1e6\n",
    "BLUE_ELUC_net     = BLUE_ELUC_net * data_2021_SUM.cell_area / 1e6\n",
    "BLUE_ELUC_sources = BLUE_ELUC_sources.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_sinks   = BLUE_ELUC_sinks.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_net     = BLUE_ELUC_net.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_sources.ELUC.attrs['unit'] = 'Tg C/year'\n",
    "BLUE_ELUC_sinks.ELUC.attrs['unit']   = 'Tg C/year'\n",
    "BLUE_ELUC_net.ELUC.attrs['unit']     = 'Tg C/year'\n",
    "\n",
    "#Define compression level\n",
    "comp = dict(zlib=True, complevel=2)\n",
    "\n",
    "#Save in file\n",
    "fname_out_sources = dir_out + 'ELUC_BLUE_GCB2021_ELUC-sources_' + time_sta + '-' + time_end + '.nc'\n",
    "fname_out_sinks = dir_out + 'ELUC_BLUE_GCB2021_ELUC-sinks_' + time_sta + '-' + time_end + '.nc'\n",
    "fname_out_net = dir_out + 'ELUC_BLUE_GCB2021_ELUC-net_' + time_sta + '-' + time_end + '.nc'\n",
    "BLUE_ELUC_sources.to_netcdf(fname_out_sources, encoding={var: comp for var in BLUE_ELUC_sources.data_vars})\n",
    "BLUE_ELUC_sinks.to_netcdf(fname_out_sinks, encoding={var: comp for var in BLUE_ELUC_sinks.data_vars})\n",
    "BLUE_ELUC_net.to_netcdf(fname_out_net, encoding={var: comp for var in BLUE_ELUC_net.data_vars})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select time\n",
    "time_sta = '2000'\n",
    "time_end = '2020'\n",
    "\n",
    "#Read ISO codes for countries, IPCC countries, and conversions between ISO alpha-3 codes from IPCC and ISO numeric\n",
    "fname_ctrs_ISO   = dir_ctrs + 'wrld_cntrs_BLUE_TN_upd.nc'\n",
    "fname_IPCC_codes = dir_ctrs + 'IPCC_regions.xlsx'\n",
    "fname_ISO_num    = dir_ctrs + 'iso_codes_alpha_numeric.xlsx'\n",
    "data_IPCC_codes = pd.read_excel(fname_IPCC_codes, sheet_name='region_classification', header=0, usecols=[0, 1, 3])\n",
    "data_alph_num   = pd.read_excel(fname_ISO_num, header=0)\n",
    "\n",
    "#Define sources, sinks, and net\n",
    "selections = ['sources', 'sinks', 'net']\n",
    "\n",
    "#Loop over sources, sinks, and net\n",
    "for selection in selections:\n",
    "\n",
    "    #Define output file name\n",
    "    fname_out = dir_out + 'ELUC_BLUE_countries-ISOcode_ELUC-' + selection + '_vRemapCountries_' + time_sta + '-' + time_end + '.xlsx'\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "\n",
    "    #Create dicts for storing data\n",
    "    ELUC_ctrs = dict()\n",
    "\n",
    "    #Create xlsx-file (it will be filled at end of loop with country data from every model)\n",
    "    with pd.ExcelWriter(fname_out) as writer:\n",
    "\n",
    "        #Read ELUC data\n",
    "        fname = dir_out + 'ELUC_BLUE_GCB2021_ELUC-' + selection + '_' + time_sta + '-' + time_end + '.nc'\n",
    "        data_ELUC = xr.open_dataset(fname)\n",
    "\n",
    "        #Regrid country ISO code to model grid\n",
    "        file_grid      = dir_out + 'grid_xy_BLUE'\n",
    "        fname_ctrs_reg = dir_tmp + 'wrld_cntrs_BLUE_TN_upd_on_BLUE_grid.nc'\n",
    "        os.system('cdo remaplaf,' + file_grid + ' ' + fname_ctrs_ISO + ' ' + fname_ctrs_reg)\n",
    "\n",
    "        #Read regridded data\n",
    "        data_ctrs_ISO = xr.open_dataset(fname_ctrs_reg)\n",
    "\n",
    "        #Get lat and lon names\n",
    "        if 'latitude' in data_ELUC.dims:  lat_name, lon_name = 'latitude', 'longitude'\n",
    "        else:                             lat_name, lon_name = 'lat', 'lon'\n",
    "\n",
    "        #Check that model grid and country grid agree\n",
    "        check_lat = np.max(np.abs(data_ELUC[lat_name].values - data_ctrs_ISO[lat_name].values))\n",
    "        check_lon = np.max(np.abs(data_ELUC[lon_name].values - data_ctrs_ISO[lon_name].values))\n",
    "        if check_lat>0.01:  sys.exit('Latitudes do not agree')\n",
    "        if check_lon>0.01:  sys.exit('Longitudes do not agree')\n",
    "\n",
    "        #Re-index if there are small deviations in lat and lon\n",
    "        if (check_lat!=0) or (check_lon!=0):\n",
    "            print('Country data are re-indexed for ' + model)\n",
    "            data_ctrs_ISO = data_ctrs_ISO.reindex({lat_name: data_ELUC[lat_name], lon_name: data_ELUC[lon_name]}, method='nearest')       \n",
    "\n",
    "        #Loop over all country codes\n",
    "        for i, iso_alpha3 in enumerate(data_IPCC_codes['ISO']):\n",
    "\n",
    "            if np.mod(i,20)==0:\n",
    "                print('  -run ' + str(i+1) + ' of ' + str(len(data_IPCC_codes['ISO'])))\n",
    "\n",
    "            #Get numbeic ISO code of country\n",
    "            iso_numeric = data_alph_num['Numeric'][data_alph_num['Alpha-3 code']==iso_alpha3].values[0]\n",
    "\n",
    "            #Select country in country mask\n",
    "            mask_ISO = data_ctrs_ISO.ISOcode==iso_numeric\n",
    "\n",
    "            #Get ELUC sum in selected country\n",
    "            data_sel = data_ELUC.where(mask_ISO).sum((lat_name, lon_name))\n",
    "\n",
    "            #Save values in dict\n",
    "            ELUC_ctrs[iso_alpha3] = data_sel.ELUC.values\n",
    "\n",
    "        #Special cases for certain IPCC countries\n",
    "        ELUC_ctrs['SXM'] = ELUC_ctrs['MAF']                                        # Saint Martin is French part of island with Sint Maarten (Dutch part) -> same values are counted for both\n",
    "        ELUC_ctrs['ANT'] = ELUC_ctrs['BES'] + ELUC_ctrs['CUW'] + ELUC_ctrs['SXM']  # Netherlands Antilles (Bonaire, Saint Eustatius & Saba + Curacao + Sint Maarten)\n",
    "\n",
    "        #Convert data to data frame (and sort by country name)\n",
    "        ELUC_ctrs_df = pd.DataFrame(ELUC_ctrs, index=data_ELUC.time)\n",
    "        ELUC_ctrs_df = ELUC_ctrs_df.reindex(sorted(ELUC_ctrs_df.columns), axis=1)\n",
    "\n",
    "        #Adde units in first cell\n",
    "        ELUC_ctrs_df = ELUC_ctrs_df.rename_axis('unit: Tg C/year')\n",
    "\n",
    "        #Create sheet in xlsx for every model and store country data\n",
    "        ELUC_ctrs_df.to_excel(writer, sheet_name='BLUE_ELUC_IPCC_ctrs', index=True, header=True, float_format='%.6f')\n",
    "\n",
    "        #Remove temporarily regridded file with ISO country codes\n",
    "        os.remove(fname_ctrs_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 unstable (using the module python3/unstable)",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
