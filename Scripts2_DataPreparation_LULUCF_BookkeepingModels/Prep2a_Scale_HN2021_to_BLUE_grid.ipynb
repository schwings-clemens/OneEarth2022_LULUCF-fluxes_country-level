{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ELUC       = '/GCB2021/Data/Output_GCB2021/202109_GCB2021_run/run_v1_1700-2021/'\n",
    "dir_ctrs       = '/Trendy/Data/data_ancillary/info_countries/'\n",
    "dir_grids      = '/Trendy/Data/grids/'\n",
    "dir_ELUC_2021  = '/GCB2021_commentary/Data/ELUC_countries/'\n",
    "dir_ELUC_NGHGI = '/GCB2021_commentary/Data/data_ELUC_NGHGI/'\n",
    "dir_peat       = '/GCB2021/Data/Peat_data/'\n",
    "dir_tmp        = '/Trendy/Data/tmp/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gridded ELUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select time\n",
    "time_sta = '2000'\n",
    "time_end = '2020'\n",
    "\n",
    "#Define necessary variables\n",
    "variables = ['CD_A', 'CD_A_c', 'CD_A_p', 'CD_A_dec_h', 'CD_A_deg_d', 'CD_A_a', 'CD_A_reg_h', 'CD_A_deg_rec_d', 'cell_area']\n",
    "\n",
    "#Read data\n",
    "file_2021_HIS = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD_PerHistoryType.nc'\n",
    "file_2021_COV = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD_PerCoverType.nc'\n",
    "file_2021_SUM = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD.nc'\n",
    "data_2021_HIS = xr.open_dataset(file_2021_HIS)\n",
    "data_2021_COV = xr.open_dataset(file_2021_COV)\n",
    "data_2021_SUM = xr.open_dataset(file_2021_SUM)\n",
    "\n",
    "#Select in time period\n",
    "data_2021_HIS = data_2021_HIS.sel(time=slice(time_sta, None))\n",
    "data_2021_COV = data_2021_COV.sel(time=slice(time_sta, None))\n",
    "data_2021_SUM = data_2021_SUM.sel(time=slice(time_sta, None))\n",
    "\n",
    "#Select variables to extract for PerHistoryType file\n",
    "variables_drop_HIS = [variab for variab in data_2021_HIS.data_vars if variab not in variables]\n",
    "variables_drop_COV = [variab for variab in data_2021_COV.data_vars if variab not in variables]\n",
    "variables_drop_SUM = [variab for variab in data_2021_SUM.data_vars if variab not in variables]\n",
    "\n",
    "data_2021_HIS = data_2021_HIS.drop(variables_drop_HIS)\n",
    "data_2021_COV = data_2021_COV.drop(variables_drop_COV)\n",
    "data_2021_SUM = data_2021_SUM.drop(variables_drop_SUM)\n",
    "\n",
    "data_sources = data_2021_COV['CD_A_c'] + data_2021_COV['CD_A_p'] + data_2021_HIS['CD_A_dec_h'] + data_2021_HIS['CD_A_deg_d']\n",
    "data_sinks   = data_2021_HIS['CD_A_a'] + data_2021_HIS['CD_A_reg_h'] + data_2021_HIS['CD_A_deg_rec_d']\n",
    "data_net     = data_2021_SUM['CD_A']\n",
    "\n",
    "#Calculate ELUC\n",
    "BLUE_ELUC_sources = data_sources.diff('time')\n",
    "BLUE_ELUC_sinks   = data_sinks.diff('time')\n",
    "BLUE_ELUC_net     = data_net.diff('time')\n",
    "BLUE_ELUC_sources['time'] = BLUE_ELUC_sources['time'] - 1\n",
    "BLUE_ELUC_sinks['time']   = BLUE_ELUC_sinks['time'] - 1\n",
    "BLUE_ELUC_net['time']     = BLUE_ELUC_net['time'] - 1\n",
    "BLUE_ELUC_sources = BLUE_ELUC_sources.sel(time=slice(time_sta, time_end))\n",
    "BLUE_ELUC_sinks   = BLUE_ELUC_sinks.sel(time=slice(time_sta, time_end))\n",
    "BLUE_ELUC_net     = BLUE_ELUC_net.sel(time=slice(time_sta, time_end))\n",
    "\n",
    "#Convert to dataset and set units\n",
    "BLUE_ELUC_sources = BLUE_ELUC_sources.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_sinks   = BLUE_ELUC_sinks.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_net     = BLUE_ELUC_net.to_dataset(name='ELUC')\n",
    "BLUE_ELUC_sources.ELUC.attrs['unit'] = 'Tg C/year'\n",
    "BLUE_ELUC_sinks.ELUC.attrs['unit']   = 'Tg C/year'\n",
    "BLUE_ELUC_net.ELUC.attrs['unit']     = 'Tg C/year'\n",
    "\n",
    "#Define compression level\n",
    "comp = dict(zlib=True, complevel=2)\n",
    "\n",
    "#Save in file\n",
    "fname_out_sources = dir_ELUC_2021 + 'ELUC_BLUE_GCB2021_ELUC-sources-density_' + time_sta + '-' + time_end + '.nc'\n",
    "fname_out_sinks = dir_ELUC_2021 + 'ELUC_BLUE_GCB2021_ELUC-sinks-density_' + time_sta + '-' + time_end + '.nc'\n",
    "fname_out_net = dir_ELUC_2021 + 'ELUC_BLUE_GCB2021_ELUC-net-density_' + time_sta + '-' + time_end + '.nc'\n",
    "if os.path.exists(fname_out_sources): os.remove(fname_out_sources)\n",
    "if os.path.exists(fname_out_sinks): os.remove(fname_out_sinks)\n",
    "if os.path.exists(fname_out_net): os.remove(fname_out_net)\n",
    "BLUE_ELUC_sources.to_netcdf(fname_out_sources, encoding={var: comp for var in BLUE_ELUC_sources.data_vars})\n",
    "BLUE_ELUC_sinks.to_netcdf(fname_out_sinks, encoding={var: comp for var in BLUE_ELUC_sinks.data_vars})\n",
    "BLUE_ELUC_net.to_netcdf(fname_out_net, encoding={var: comp for var in BLUE_ELUC_net.data_vars})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ELUC BLUE (GCB2021, without peat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sta = 2000\n",
    "time_end = 2020\n",
    "time_len = time_end - time_sta + 1\n",
    "\n",
    "#Read ELUC data and peat data\n",
    "fname_BLUE_snk = dir_ELUC_2021 + 'ELUC_BLUE_countries-ISOcode_ELUC-sinks_vRemapCountries_2000-2020.xlsx'\n",
    "fname_BLUE_src = dir_ELUC_2021 + 'ELUC_BLUE_countries-ISOcode_ELUC-sources_vRemapCountries_2000-2020.xlsx'\n",
    "ELUC_BLUE_snk = pd.read_excel(fname_BLUE_snk, header=0, index_col=0)\n",
    "ELUC_BLUE_src = pd.read_excel(fname_BLUE_src, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "ELUC_BLUE_snk = ELUC_BLUE_snk.loc[(ELUC_BLUE_snk.index>=time_sta) & (ELUC_BLUE_snk.index<=time_end)]\n",
    "ELUC_BLUE_src = ELUC_BLUE_src.loc[(ELUC_BLUE_src.index>=time_sta) & (ELUC_BLUE_src.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (ELUC_BLUE_snk.index[0]!=time_sta) | (ELUC_BLUE_snk.index[-1]!=time_end) | (len(ELUC_BLUE_snk.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "if (ELUC_BLUE_src.index[0]!=time_sta) | (ELUC_BLUE_src.index[-1]!=time_end) | (len(ELUC_BLUE_src.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "\n",
    "# UNITS: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ELUC H&N2021 (GCB2021, without peat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data and peat data\n",
    "fname_HN21_snk = dir_ELUC_NGHGI + 'HN2021_ELUC-sinks_GCB2021_countries.xlsx'\n",
    "fname_HN21_src = dir_ELUC_NGHGI + 'HN2021_ELUC-sources_GCB2021_countries.xlsx'\n",
    "ELUC_HN21_snk = pd.read_excel(fname_HN21_snk, header=0, index_col=0)\n",
    "ELUC_HN21_src = pd.read_excel(fname_HN21_src, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "ELUC_HN21_snk = ELUC_HN21_snk.loc[(ELUC_HN21_snk.index>=time_sta) & (ELUC_HN21_snk.index<=time_end)]\n",
    "ELUC_HN21_src = ELUC_HN21_src.loc[(ELUC_HN21_src.index>=time_sta) & (ELUC_HN21_src.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (ELUC_HN21_snk.index[0]!=time_sta) | (ELUC_HN21_snk.index[-1]!=time_end) | (len(ELUC_HN21_snk.index)!=time_len):  sys.exit('Check time selection of H&N2021!')\n",
    "if (ELUC_HN21_src.index[0]!=time_sta) | (ELUC_HN21_src.index[-1]!=time_end) | (len(ELUC_HN21_src.index)!=time_len):  sys.exit('Check time selection of H&N2021!')\n",
    "\n",
    "# UNITS: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select time\n",
    "time_sta = '2000'\n",
    "time_end = '2020'\n",
    "\n",
    "#Read ISO codes for countries, IPCC countries, and conversions between ISO alpha-3 codes from IPCC and ISO numeric\n",
    "fname_ctrs_ISO   = dir_ctrs + 'wrld_cntrs_BLUE_TN_upd.nc'\n",
    "fname_IPCC_codes = dir_ctrs + 'IPCC_regions.xlsx'\n",
    "fname_ISO_num    = dir_ctrs + 'iso_codes_alpha_numeric.xlsx'\n",
    "fname_cntrs_3LET = dir_ctrs + 'Country codes 3 letters.xlsx'\n",
    "data_IPCC_codes = pd.read_excel(fname_IPCC_codes, sheet_name='region_classification', header=0, usecols=[0, 1, 3])\n",
    "data_alph_num   = pd.read_excel(fname_ISO_num, header=0)\n",
    "data_cntrs_3LET = pd.read_excel(fname_cntrs_3LET, sheet_name=0, header=None, index_col=0)\n",
    "\n",
    "#Regrid country ISO code to model grid\n",
    "file_grid      = dir_grids + 'grid_xy_BLUE'\n",
    "fname_ctrs_reg = dir_tmp + 'wrld_cntrs_BLUE_TN_upd_on_BLUE_grid.nc'\n",
    "if os.path.exists(fname_ctrs_reg): os.remove(fname_ctrs_reg)\n",
    "os.system('cdo remaplaf,' + file_grid + ' ' + fname_ctrs_ISO + ' ' + fname_ctrs_reg)\n",
    "\n",
    "#Read regridded country ISO data\n",
    "data_ctrs_ISO = xr.open_dataset(fname_ctrs_reg)\n",
    "\n",
    "#Read BLUE ELUC on grid (sources and sinks)\n",
    "fname_BLUE_snk_grid = dir_ELUC_2021 + 'ELUC_BLUE_GCB2021_ELUC-sinks-density_' + time_sta + '-' + time_end + '.nc'\n",
    "fname_BLUE_src_grid = dir_ELUC_2021 + 'ELUC_BLUE_GCB2021_ELUC-sources-density_' + time_sta + '-' + time_end + '.nc'\n",
    "data_BLUE_snk_grid = xr.open_dataset(fname_BLUE_snk_grid)\n",
    "data_BLUE_src_grid = xr.open_dataset(fname_BLUE_src_grid)\n",
    "\n",
    "#Read area of BLUE grid\n",
    "fname_area = dir_ELUC + '202109_GCB2021_run_v1_1700-2021__CurrentCPools_CD.nc'\n",
    "data_area = xr.open_dataset(fname_area)\n",
    "data_area = data_area.cell_area\n",
    "\n",
    "#Get ISO values of all countries\n",
    "ISO_values = np.unique(data_ctrs_ISO.ISOcode.values)\n",
    "ISO_values = ISO_values[~np.isnan(ISO_values)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = ''\n",
    "\n",
    "#List for collecting missing H&N countries\n",
    "ctr_missing_HN = []\n",
    "ctr_check = pd.DataFrame(columns=['test_perc', 'test_abs'])\n",
    "\n",
    "#Loop over all countries/ISO values\n",
    "create = 1\n",
    "create2 = 1\n",
    "for i, ISO_val in enumerate(ISO_values):\n",
    "    \n",
    "    if np.mod(i,10)==0:\n",
    "        print('')\n",
    "        print('Run ' + str(i+1) + ' of ' + str(len(ISO_values)), end=': ')\n",
    "        \n",
    "    print(int(ISO_val), end=', ')\n",
    "    \n",
    "    #Get country names\n",
    "    country   = data_alph_num[data_alph_num['Numeric']==ISO_val]\n",
    "    ctr_short = country['Alpha-3 code'].values[0]\n",
    "    ctr_long  = data_cntrs_3LET.loc[ctr_short].item()\n",
    "\n",
    "    #Adjust some country names to fit H&N2021 naming\n",
    "    if \"Bolivia (Plurinational State of)\" in ctr_long:                        ctr_long = \"Bolivia\"\n",
    "    elif \"Congo, Democratic Republic of the\" in ctr_long:                     ctr_long = \"Democratic Republic of the Congo\"\n",
    "    elif \"CÃ´te d'Ivoire\" in ctr_long:                                         ctr_long = \"Cote d'Ivoire\"\n",
    "    elif \"Czechia\" in ctr_long:                                               ctr_long = \"Czech Republic\"\n",
    "    elif \"Guinea-Bissau\" in ctr_long:                                         ctr_long = \"Guinea Bissau\"\n",
    "    elif \"Iran (Islamic Republic of)\" in ctr_long:                            ctr_long = \"Iran\"\n",
    "    elif \"Korea (Democratic People's Republic of)\" in ctr_long:               ctr_long = \"Democratic People's Republic of the Korea\"\n",
    "    elif \"Korea, Republic of\" in ctr_long:                                    ctr_long = \"Republic of Korea\"\n",
    "    elif \"North Macedonia\" in ctr_long:                                       ctr_long = \"The former Yugoslav Republic of Macedonia\"\n",
    "    elif \"Moldova, Republic of\" in ctr_long:                                  ctr_long = \"Republic of Moldova\"\n",
    "    elif \"Tanzania, United Republic of\" in ctr_long:                          ctr_long = \"United Republic of Tanzania\"\n",
    "    elif \"United Kingdom of Great Britain and Northern Ireland\" in ctr_long:  ctr_long = \"United Kingdom\"\n",
    "    elif \"Venezuela (Bolivarian Republic of)\" in ctr_long:                    ctr_long = \"Venezuela\"\n",
    "    elif \"Cabo Verde\" in ctr_long:                                            ctr_long = \"Cape Verde\"  \n",
    "\n",
    "    #Read H&N2021 country data\n",
    "    try:\n",
    "        sel_HN2021_snk = ELUC_HN21_snk[ctr_long].to_frame(ctr_short)\n",
    "        sel_HN2021_src = ELUC_HN21_src[ctr_long].to_frame(ctr_short)\n",
    "    except:\n",
    "        sel_HN2021_snk = pd.DataFrame(np.NaN, columns=[ctr_short], index=ELUC_BLUE_snk.index)\n",
    "        sel_HN2021_src = pd.DataFrame(np.NaN, columns=[ctr_short], index=ELUC_BLUE_src.index)\n",
    "        sel_HN2021_snk = sel_HN2021_snk.rename_axis('index')\n",
    "        sel_HN2021_src = sel_HN2021_src.rename_axis('index')\n",
    "        ctr_missing_HN.append(ctr_long)\n",
    "        \n",
    "    #Read BLUE country data\n",
    "    if ctr_short=='CHN':\n",
    "        sel_BLUE_snk = ELUC_BLUE_snk['CHN'] + ELUC_BLUE_snk['TWN'] + ELUC_BLUE_snk['HKG']\n",
    "        sel_BLUE_src = ELUC_BLUE_src['CHN'] + ELUC_BLUE_src['TWN'] + ELUC_BLUE_src['HKG']\n",
    "        \n",
    "    else:\n",
    "        sel_BLUE_snk = ELUC_BLUE_snk[ctr_short].copy(deep=True)\n",
    "        sel_BLUE_src = ELUC_BLUE_src[ctr_short].copy(deep=True)\n",
    "    \n",
    "    #Convert to data frame\n",
    "    sel_BLUE_snk = sel_BLUE_snk.to_frame(ctr_short)\n",
    "    sel_BLUE_src = sel_BLUE_src.to_frame(ctr_short)\n",
    "\n",
    "    #Calculate scale factor\n",
    "    scale_fac_snk = sel_HN2021_snk / sel_BLUE_snk\n",
    "    scale_fac_src = sel_HN2021_src / sel_BLUE_src\n",
    "    scale_fac_snk[np.isinf(scale_fac_snk)] = np.NaN\n",
    "    scale_fac_src[np.isinf(scale_fac_src)] = np.NaN\n",
    "    \n",
    "    #Rename scale factor and set NaNs to 0\n",
    "    scale_fac_snk = scale_fac_snk.rename(columns={ctr_short: 'scale_factor'})\n",
    "    scale_fac_src = scale_fac_src.rename(columns={ctr_short: 'scale_factor'})\n",
    "    scale_fac_snk[np.isnan(scale_fac_snk)] = 0\n",
    "    scale_fac_src[np.isnan(scale_fac_src)] = 0\n",
    "    \n",
    "    #convert scale factor to xarray\n",
    "    scale_snk_xr = scale_fac_snk.to_xarray()\n",
    "    scale_src_xr = scale_fac_src.to_xarray()\n",
    "    scale_snk_xr = scale_snk_xr.rename({'index': 'time'})\n",
    "    scale_src_xr = scale_src_xr.rename({'index': 'time'})\n",
    "    \n",
    "    #Get gridded data in selected country (add Taiwan and Hongkong to China)\n",
    "    if ctr_short=='CHN':\n",
    "        sel1 = data_ctrs_ISO.ISOcode==data_alph_num[data_alph_num['Alpha-3 code']=='CHN']['Numeric'].values[0]\n",
    "        sel2 = data_ctrs_ISO.ISOcode==data_alph_num[data_alph_num['Alpha-3 code']=='TWN']['Numeric'].values[0]\n",
    "        sel3 = data_ctrs_ISO.ISOcode==data_alph_num[data_alph_num['Alpha-3 code']=='HKG']['Numeric'].values[0]\n",
    "        sel_country = sel1 + sel2 + sel3\n",
    "    else:\n",
    "        sel_country = data_ctrs_ISO.ISOcode==ISO_val\n",
    "        \n",
    "    sel_BLUE_grid_snk = data_BLUE_snk_grid.where(sel_country, 0)\n",
    "    sel_BLUE_grid_src = data_BLUE_src_grid.where(sel_country, 0)\n",
    "\n",
    "    #Collect country selection for overall check\n",
    "    if create2==1:\n",
    "        data_mask_all = 1 * (data_ctrs_ISO.ISOcode==ISO_val)\n",
    "        create2 = 0\n",
    "    else:\n",
    "        data_mask_all = data_mask_all + 1 * (data_ctrs_ISO.ISOcode==ISO_val)\n",
    "    \n",
    "    #Apply scale factor\n",
    "    if version=='_vMean':\n",
    "        sel_BLUE_grid_snk = sel_BLUE_grid_snk.sel(time=slice('2001', '2015'))\n",
    "        sel_BLUE_grid_src = sel_BLUE_grid_src.sel(time=slice('2001', '2015'))\n",
    "        scale_snk_xr      = scale_snk_xr.sel(time=slice('2001', '2015'))\n",
    "        scale_src_xr      = scale_src_xr.sel(time=slice('2001', '2015'))\n",
    "        data_HN21_snk_scaled = sel_BLUE_grid_snk.mean('time') * scale_snk_xr.scale_factor.mean('time')\n",
    "        data_HN21_src_scaled = sel_BLUE_grid_src.mean('time') * scale_src_xr.scale_factor.mean('time')\n",
    "    else:\n",
    "        data_HN21_snk_scaled = sel_BLUE_grid_snk * scale_snk_xr.scale_factor\n",
    "        data_HN21_src_scaled = sel_BLUE_grid_src * scale_src_xr.scale_factor\n",
    "    \n",
    "    #Distribute HN2021 ELUC sinks equally in country if BLUE ELUC is 0\n",
    "    if np.any(sel_BLUE_snk==0):\n",
    "        \n",
    "        #Get countr area,  calculate sink density in country and sSelect times when BLUE is 0\n",
    "        area_ctr = (data_area * sel_country).sum(('lat', 'lon')).values.item()\n",
    "        density_snk = sel_HN2021_snk / area_ctr * 1e6 # unit: tC / ha\n",
    "        density_snk[np.isnan(density_snk)] = 0\n",
    "        density_snk_xr = density_snk.to_xarray().rename({'index': 'time'})\n",
    "        density_snk_grid = density_snk_xr * sel_country\n",
    "        density_snk_grid = density_snk_grid.rename({ctr_short: 'ELUC'})        \n",
    "        select_time_snk = (sel_BLUE_snk!=0).to_xarray()\n",
    "        select_time_snk = select_time_snk.rename({ctr_short: 'ELUC', [name for name in select_time_snk.coords][0]:'time'})\n",
    "        \n",
    "        #Add calculated density to grid\n",
    "        data_HN21_snk_scaled = data_HN21_snk_scaled.where(select_time_snk, density_snk_grid)\n",
    "        \n",
    "    #Distribute HN2021 ELUC sources equally in country if BLUE ELUC is 0\n",
    "    if np.any(sel_BLUE_src==0):\n",
    "        \n",
    "        #Get countr area, calculate sink density in country and sSelect times when BLUE is 0\n",
    "        area_ctr = (data_area * sel_country).sum(('lat', 'lon')).values.item()\n",
    "        density_src = sel_HN2021_src / area_ctr * 1e6 # unit: tC / ha\n",
    "        density_src[np.isnan(density_src)] = 0\n",
    "        density_src_xr = density_src.to_xarray().rename({'index': 'time'})\n",
    "        density_src_grid = density_src_xr * sel_country\n",
    "        density_src_grid = density_src_grid.rename({ctr_short: 'ELUC'})\n",
    "        select_time_src = (sel_BLUE_src!=0).to_xarray()\n",
    "        select_time_src = select_time_src.rename({ctr_short: 'ELUC', [name for name in select_time_src.coords][0]:'time'})\n",
    "        \n",
    "        #Add calculated density to grid\n",
    "        data_HN21_src_scaled = data_HN21_src_scaled.where(select_time_src, density_src_grid)\n",
    "        \n",
    "    #Collect in dataset\n",
    "    if create==1:\n",
    "        data_HN2021_grid_snk = data_HN21_snk_scaled\n",
    "        data_HN2021_grid_src = data_HN21_src_scaled\n",
    "        create = 0\n",
    "    else:\n",
    "        data_HN2021_grid_snk = data_HN2021_grid_snk + ds_drain\n",
    "        data_HN2021_grid_src = data_HN2021_grid_src + data_HN21_src_scaled\n",
    "\n",
    "    if np.sum(~np.isnan(data_HN2021_grid_snk.isel(time=0).ELUC))==0:\n",
    "        sdafasf        \n",
    "\n",
    "        \n",
    "#Define output file name\n",
    "fname_out_snk = dir_ELUC_2021 + 'ELUC_H&N_GCB2021_ELUC-sinks-density_' + str(time_sta) + '-' + str(time_end) + version + '.nc'\n",
    "fname_out_src = dir_ELUC_2021 + 'ELUC_H&N_GCB2021_ELUC-sources-density_' + str(time_sta) + '-' + str(time_end) + version + '.nc'\n",
    "if os.path.exists(fname_out_snk): os.remove(fname_out_snk)\n",
    "if os.path.exists(fname_out_src): os.remove(fname_out_src)\n",
    "data_HN2021_grid_snk.to_netcdf(fname_out_snk)\n",
    "data_HN2021_grid_src.to_netcdf(fname_out_src)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clemens Python3.10",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
