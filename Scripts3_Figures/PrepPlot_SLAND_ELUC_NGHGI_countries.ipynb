{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f41528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580ba52",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ELUC_NGHGI = '/Data/data_ELUC_NGHGI/'\n",
    "dir_SLAND      = '/Data/SLAND_Trendy-v10_S2_countries/'\n",
    "dir_ctrs       = '/Data/data_ancillary/info_countries/'\n",
    "dir_ELUC_2021  = '/Data/ELUC_countries/'\n",
    "dir_peat       = '/Data/Peat_data/'\n",
    "dir_out        = '/Data/data_ELUC_NGHGI_SLAND_plot/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4b81a",
   "metadata": {},
   "source": [
    "## Read country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c219db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_cntrs = dir_ctrs + 'Country codes 3 letters.xlsx'\n",
    "data_cntrs  = pd.read_excel(fname_cntrs, sheet_name=0, header=None, index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98744525",
   "metadata": {},
   "source": [
    "## Define time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define time\n",
    "time_sta = 2001\n",
    "time_end = 2015\n",
    "time_len = time_end - time_sta + 1\n",
    "time_str = str(time_sta) + '-' + str(time_end)\n",
    "\n",
    "print(time_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4864ef",
   "metadata": {},
   "source": [
    "## Read SLAND data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_SLAND = ['CABLE-POP', 'CLASSIC', 'CLM5.0', 'DLEM', 'IBIS', 'ISAM', 'ISBA-CTRIP', 'JSBACH', 'JULES-ES-1.1',\n",
    "                'LPJ-GUESS', 'LPJwsl', 'LPX-Bern', 'OCN', 'ORCHIDEEv3', 'SDGVM', 'VISIT', 'YIBs']#'CLASSIC-N', 'ORCHIDEE'\n",
    "\n",
    "#Define parameters to select datasets\n",
    "selection      = 'non-intact-forests'\n",
    "data_set       = 'DGVMs-Forests-PFTs'\n",
    "Han2013_thresh = 0.20\n",
    "\n",
    "#Define file names\n",
    "fname_SLAND_total_weighted       = dir_SLAND + 'SLAND-S2-countries_Weights-DGVMs-Forests-PFTs_total-SLAND_vRemapToForestMask-Hansen2010_IFL_2013_v2.xlsx'\n",
    "fname_SLAND_forest2013_nonintact = dir_SLAND + 'SLAND-S2-countries_' + selection + '_Weights-' + data_set + '_MaxForCover' + '{:.2f}'.format(Han2013_thresh) + '_vRemapToForestMask-Hansen2010_IFL_2013_v2.xlsx'\n",
    "\n",
    "\n",
    "#Collect all file names and names for dictionary\n",
    "SLAND_versions= dict()\n",
    "SLAND_versions['SLAND_total-weighted']             = fname_SLAND_total_weighted\n",
    "SLAND_versions['SLAND_non-intact-forest_mask2013'] = fname_SLAND_forest2013_nonintact\n",
    "\n",
    "#Dictionary for storing data\n",
    "data_SLAND = dict()\n",
    "\n",
    "for name_out, fname in SLAND_versions.items():\n",
    "\n",
    "    print('Read data for ' + name_out, end=': ')\n",
    "    \n",
    "    #Create empyt dataframes\n",
    "    data_SLAND_coll = pd.DataFrame()\n",
    "    \n",
    "    #Loop over models\n",
    "    for model in models_SLAND:\n",
    "        \n",
    "        print(model, end=', ')\n",
    "        \n",
    "        #Read SLAND data\n",
    "        data_SLAND_read = pd.read_excel(fname, sheet_name=model + '_SLAND_IPCC_ctrs', header=0, index_col=0)\n",
    "        \n",
    "        #Select time\n",
    "        data_SLAND_read = data_SLAND_read.loc[(data_SLAND_read.index>=time_sta) & (data_SLAND_read.index<=time_end)]\n",
    "        \n",
    "        #Check time selection\n",
    "        if (data_SLAND_read.index[0]!=time_sta) | (data_SLAND_read.index[-1]!=time_end) | (len(data_SLAND_read.index)!=time_len):\n",
    "            sys.exit('Check time selection of SLAND!')\n",
    "        \n",
    "        #Calculate time average\n",
    "        data_SLAND_read = data_SLAND_read.mean(axis=0)\n",
    "        \n",
    "        #Set correct sign vor SLAND\n",
    "        data_SLAND_coll[model] = -data_SLAND_read\n",
    "\n",
    "    #Save in dictionary\n",
    "    data_SLAND[name_out] = data_SLAND_coll\n",
    "    \n",
    "    print('')\n",
    "    print('{:.1f}'.format(data_SLAND_coll.sum(axis=0).mean() * 44 / 12 / 1000) + ' Pg CO2 / year')\n",
    "    print('')\n",
    "    \n",
    "## UNITS\n",
    "#data_SLAND has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ca324",
   "metadata": {},
   "source": [
    "## Read peat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read peat data\n",
    "fname_peat_drai = dir_peat + 'Country_emissions_peat-drainage_FAO_1850-2021.xlsx'\n",
    "fname_peat_fire = dir_peat + 'Country_emissions_peat-fires_GFED4_1997-2021.xlsx'\n",
    "data_peat_in_1 = pd.read_excel(fname_peat_drai, header=0, index_col=0)\n",
    "data_peat_in_2 = pd.read_excel(fname_peat_fire, header=0, index_col=0)\n",
    "data_peat_in_1 = data_peat_in_1.loc[(data_peat_in_1.index>=time_sta) & (data_peat_in_1.index<=time_end)]\n",
    "data_peat_in_2 = data_peat_in_2.loc[(data_peat_in_2.index>=time_sta) & (data_peat_in_2.index<=time_end)]\n",
    "\n",
    "#Select time\n",
    "if (data_peat_in_1.index[0]!=time_sta) | (data_peat_in_1.index[-1]!=time_end) | (len(data_peat_in_1.index)!=time_len):  sys.exit('Check time selection of peat 1!')\n",
    "if (data_peat_in_2.index[0]!=time_sta) | (data_peat_in_2.index[-1]!=time_end) | (len(data_peat_in_2.index)!=time_len):  sys.exit('Check time selection of peat 2!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa463a34",
   "metadata": {},
   "source": [
    "## Read data BLUE (LUH2021) and add peat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data\n",
    "fname_ELUC  = dir_ELUC_2021 + 'ELUC_BLUE_countries-ISOcode_ELUC-net_vRemapCountries_2000-2020.xlsx'\n",
    "data_BLUE_read = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_BLUE_read = data_BLUE_read.loc[(data_BLUE_read.index>=time_sta) & (data_BLUE_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_BLUE_read.index[0]!=time_sta) | (data_BLUE_read.index[-1]!=time_end) | (len(data_BLUE_read.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "\n",
    "#Create empty dataframe\n",
    "data_ELUC_BLUE_2021_all = data_BLUE_read.copy()\n",
    "data_ELUC_BLUE_2021_all[:] = np.NaN\n",
    "\n",
    "#Loop over all countries\n",
    "for col in data_BLUE_read.columns:\n",
    "    \n",
    "    #Sum ELUC and peat\n",
    "    if col in data_peat_in_1.columns:\n",
    "        data_BLUE_read[col] = data_BLUE_read[col] + data_peat_in_1[col]\n",
    "    if col in data_peat_in_2.columns:\n",
    "        data_BLUE_read[col] = data_BLUE_read[col] + data_peat_in_2[col]\n",
    "\n",
    "    #Save in dataframe\n",
    "    data_ELUC_BLUE_2021_all[col] = data_BLUE_read[col]\n",
    "\n",
    "#Calculate time average\n",
    "data_ELUC_BLUE_2021 = data_ELUC_BLUE_2021_all.mean(axis=0)\n",
    "\n",
    "#Convert to dataframe and convert to Tg C / year\n",
    "data_ELUC_BLUE_2021 = data_ELUC_BLUE_2021.to_frame(name='ELUC')\n",
    "\n",
    "## UNITS\n",
    "#data_ELUC_BLUE_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd486c4",
   "metadata": {},
   "source": [
    "## Read ELUC H&N2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821994b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data (which already include peat)\n",
    "fname_ELUC = dir_ELUC_NGHGI + 'HN2021_ELUC-net-with-peat_GCB2021_countries.xlsx'\n",
    "data_HN2021_read  = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_HN2021_read = data_HN2021_read.loc[(data_HN2021_read.index>=time_sta) & (data_HN2021_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_HN2021_read.index[0]!=time_sta) | (data_HN2021_read.index[-1]!=time_end) | (len(data_HN2021_read.index)!=time_len):  sys.exit('Check time selection of H&N2021!')\n",
    "\n",
    "#Calculate time average\n",
    "data_ELUC_HN_2021 = data_HN2021_read.mean(axis=0)\n",
    "\n",
    "#Convert to dataframe and convert to Tg C / year\n",
    "data_ELUC_HN_2021 = data_ELUC_HN_2021.to_frame(name='ELUC')\n",
    "      \n",
    "## UNITS\n",
    "#data_ELUC_HN_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2185cf3e",
   "metadata": {},
   "source": [
    "## Correct peak in 2010 for DR Congo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_COD = 0\n",
    "if correct_COD==1:\n",
    "\n",
    "    print(data_ELUC_BLUE_2021_all['COD'].mean())\n",
    "    data_ELUC_BLUE_2021_all['COD'].loc[slice(2010, None)] = data_HN2021_read['Democratic Republic of the Congo'].loc[slice(2010, None)].values\n",
    "\n",
    "    print(data_ELUC_BLUE_2021_all['COD'].mean())\n",
    "    data_ELUC_BLUE_2021.loc['COD'] = data_ELUC_BLUE_2021_all['COD'].mean()\n",
    "    \n",
    "    outname = '_CODcorrected'\n",
    "else:\n",
    "    outname = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b2fb5",
   "metadata": {},
   "source": [
    "## Read OSCAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba709a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data \n",
    "fname_ELUC = dir_ELUC_NGHGI + 'OSCAR_ELUC-net-with-peat_GCB2021_IPCCcountries.xlsx'\n",
    "data_OSCAR_read = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_OSCAR_read = data_OSCAR_read.loc[(data_OSCAR_read.index>=time_sta) & (data_OSCAR_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_OSCAR_read.index[0]!=time_sta) | (data_OSCAR_read.index[-1]!=time_end) | (len(data_OSCAR_read.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "\n",
    "#Calculate time average\n",
    "data_ELUC_OSCAR_2021 = data_OSCAR_read.mean(axis=0)\n",
    "    \n",
    "#Convert to dataframe and convert to Tg C / year\n",
    "data_ELUC_OSCAR_2021 = data_ELUC_OSCAR_2021.to_frame(name='ELUC')\n",
    "   \n",
    "## UNITS\n",
    "#data_ELUC_OSCAR_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012d41a",
   "metadata": {},
   "source": [
    "## Read data NGHGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data   \n",
    "fname_NGHGI = dir_ELUC_NGHGI + 'Grassi_Giacomo_NGHGI_2021_11_preliminary.xlsx'\n",
    "data_NGHGI  = pd.read_excel(fname_NGHGI, sheet_name='summary DB2', header=2, index_col=0)\n",
    "\n",
    "#Read new data for Indonesia\n",
    "fname_IDN = dir_ELUC_NGHGI + 'LULUCF_Indonesia_UNFCCC_BUR3.xlsx'\n",
    "data_IDN  = pd.read_excel(fname_IDN, header=0, index_col=0)\n",
    "\n",
    "#Get column and index names\n",
    "data_NGHGI.columns = data_NGHGI.iloc[0]\n",
    "data_NGHGI.index = data_NGHGI['ISO']\n",
    "\n",
    "#Select data\n",
    "data_NGHGI = data_NGHGI.iloc[1:196, 12:16]\n",
    "data_NGHGI = data_NGHGI.astype(float)\n",
    "\n",
    "#Prepare data for China\n",
    "data_China = pd.DataFrame(columns=['NGHGI'], index=np.arange(2000, 2021))\n",
    "# data_China.loc[1994] =  -407479 / 1000\n",
    "data_China.loc[2005] =  -803000 / 1000\n",
    "data_China.loc[2010] = -1029720 / 1000\n",
    "data_China.loc[2012] =  -575848 / 1000\n",
    "data_China.loc[2014] = -1150910 / 1000\n",
    "data_China = data_China.astype(float)\n",
    "\n",
    "#Interpolate and extrapolate data\n",
    "data_China = data_China.interpolate(limit_direction='both')\n",
    "\n",
    "#Add data to NGHGI\n",
    "data_NGHGI.loc['CHN'][0] = data_China[(data_China.index>=2001) & (data_China.index<=2005)].mean()\n",
    "data_NGHGI.loc['CHN'][1] = data_China[(data_China.index>=2006) & (data_China.index<=2010)].mean()\n",
    "data_NGHGI.loc['CHN'][2] = data_China[(data_China.index>=2011) & (data_China.index<=2015)].mean()\n",
    "data_NGHGI.loc['CHN'][3] = data_China[(data_China.index>=2016) & (data_China.index<=2020)].mean()\n",
    "\n",
    "#Define index for time selection (start)\n",
    "if time_sta==2001:  i_sta = 0\n",
    "else:               sys.exit('Start time is not well defined for NGHGI')\n",
    "\n",
    "#Define index for time selection (end)\n",
    "if time_end==2010:    i_end = 2\n",
    "elif time_end==2015:  i_end = 3\n",
    "elif time_end==2020:  i_end = 4\n",
    "else:                 sys.exit('End time is not well defined for NGHGI')\n",
    "\n",
    "#Select time and calculate average\n",
    "data_NGHGI = data_NGHGI.iloc[:, i_sta:i_end].mean(axis=1)\n",
    "data_NGHGI = pd.Series(data_NGHGI, index = data_NGHGI.index).to_frame(name='NGHGI')\n",
    "\n",
    "#Calculate average for Indonesia in selected period and add replace old NGHGI data of IDN\n",
    "data_IDN  = data_IDN[data_IDN.columns[(data_IDN.columns>=time_sta) & (data_IDN.columns<=time_end)]].mean(axis=1)\n",
    "data_NGHGI.loc['IDN'] = data_IDN['LULUCF flux'] / 1000\n",
    "\n",
    "#Convert from Mt CO2 yr-1 to Mt C yr-1 (=Tg C / year)\n",
    "data_NGHGI = 12 / 44 * data_NGHGI\n",
    "\n",
    "## UNITS\n",
    "#data_NGHGI has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cce44b",
   "metadata": {},
   "source": [
    "## Add REDD+ data for DR Congo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33619ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data   \n",
    "fname_REDD = dir_ELUC_NGHGI + 'REDDplus_DRC.xlsx'\n",
    "data_REDD  = pd.read_excel(fname_REDD, header=1, index_col=1)\n",
    "\n",
    "#Select data and time period\n",
    "data_REDD = data_REDD.iloc[0:3,1::]\n",
    "data_REDD = data_REDD.loc['Net']\n",
    "data_REDD = data_REDD[(data_REDD.index>=time_sta) & (data_REDD.index<=time_end)].mean()\n",
    "\n",
    "#Convert from kt CO2 yr-1 to Mt C yr-1 (=Tg C / year)\n",
    "data_REDD = 12 / 44 / 1000 * data_REDD\n",
    "\n",
    "#Add to NGHGI data\n",
    "data_NGHGI.loc['COD_REDD+', 'NGHGI'] = data_REDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4811ae",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of countries\n",
    "countries_BLUE       = data_ELUC_BLUE_2021.index\n",
    "countries_HN_2021    = data_ELUC_HN_2021.index\n",
    "countries_OSCAR_2021 = data_ELUC_OSCAR_2021.index\n",
    "countries_NGHGI   = data_NGHGI.index\n",
    "countries_check1 = set(countries_BLUE)\n",
    "countries_check3 = set(countries_HN_2021)\n",
    "countries_check4 = set(countries_OSCAR_2021)\n",
    "countries_check5 = set(countries_BLUE)\n",
    "\n",
    "#Create empty dataframes\n",
    "data_collect_ELUC_NGHGI       = pd.DataFrame()\n",
    "data_collect_ELUC_NGHGI.index = countries_BLUE\n",
    "data_collect_SLAND = dict()\n",
    "for SLAND_name in data_SLAND.keys():\n",
    "    data_collect_SLAND[SLAND_name]       = pd.DataFrame()\n",
    "    data_collect_SLAND[SLAND_name].index = countries_BLUE\n",
    "    \n",
    "#Define country list for EU27 + UK\n",
    "ctrs_EU = ['AUT', 'BEL', 'BGR', 'HRV', 'CYP', 'CZE', 'DNK', 'EST', 'FIN', 'FRA', 'DEU', 'GRC', 'HUN', 'IRL', 'ITA', 'LVA', 'LTU', 'LUX', 'MLT', 'NLD', 'POL', 'PRT', 'ROU', 'SVK', 'SVN', 'ESP', 'SWE', 'GBR']\n",
    "\n",
    "#Loop over all IPCC countries\n",
    "for i1, country in enumerate(countries_BLUE):\n",
    "\n",
    "    #Get long name for country\n",
    "    ctr_long = data_cntrs.loc[country].item()\n",
    "\n",
    "    #Adjust some country names to fit NGHGI naming\n",
    "    if \"Bolivia (Plurinational State of)\" in ctr_long:                        ctr_long = \"Bolivia\"\n",
    "    elif \"Congo, Democratic Republic of the\" in ctr_long:                     ctr_long = \"Democratic Republic of the Congo\"\n",
    "    elif \"Côte d'Ivoire\" in ctr_long:                                         ctr_long = \"Cote d'Ivoire\"\n",
    "    elif \"Czechia\" in ctr_long:                                               ctr_long = \"Czech Republic\"\n",
    "    elif \"Guinea-Bissau\" in ctr_long:                                         ctr_long = \"Guinea Bissau\"\n",
    "    elif \"Iran (Islamic Republic of)\" in ctr_long:                            ctr_long = \"Iran\"\n",
    "    elif \"Korea (Democratic People's Republic of)\" in ctr_long:               ctr_long = \"Democratic People's Republic of the Korea\"\n",
    "    elif \"Korea, Republic of\" in ctr_long:                                    ctr_long = \"Republic of Korea\"\n",
    "    elif \"North Macedonia\" in ctr_long:                                       ctr_long = \"The former Yugoslav Republic of Macedonia\"\n",
    "    elif \"Moldova, Republic of\" in ctr_long:                                  ctr_long = \"Republic of Moldova\"\n",
    "    elif \"Tanzania, United Republic of\" in ctr_long:                          ctr_long = \"United Republic of Tanzania\"\n",
    "    elif \"United Kingdom of Great Britain and Northern Ireland\" in ctr_long:  ctr_long = \"United Kingdom\"\n",
    "    elif \"Venezuela (Bolivarian Republic of)\" in ctr_long:                    ctr_long = \"Venezuela\"\n",
    "    elif \"Cabo Verde\" in ctr_long:                                            ctr_long = \"Cape Verde\"  \n",
    "\n",
    "    #Extract NGHGI values\n",
    "    try:\n",
    "        NGHGI_val = data_NGHGI.loc[country].item()\n",
    "        countries_check1.discard(country)\n",
    "    except:\n",
    "        NGHGI_val = np.NaN\n",
    "        if np.abs(data_ELUC_BLUE_2021.loc[country].item())>0.05:\n",
    "            print('No NGHGI data for ' + ctr_long)\n",
    "\n",
    "    #Extract ELUC for H&N2021\n",
    "    try:\n",
    "        ELUC_HN_2021_val = data_ELUC_HN_2021.loc[ctr_long].item()\n",
    "        countries_check3.discard(ctr_long)\n",
    "    except:\n",
    "        ELUC_HN_2021_val = np.NaN        \n",
    "    \n",
    "    #Extract ELUC for OSCAR (GCB2021)\n",
    "    try:\n",
    "        ELUC_OSCAR_2021_val = data_ELUC_OSCAR_2021.loc[country].item()\n",
    "        countries_check4.discard(country)\n",
    "    except:\n",
    "        ELUC_OSCAR_2021_val = np.NaN           \n",
    "    \n",
    "    #Extract SLAND values\n",
    "    SLAND_coll = pd.DataFrame()\n",
    "    for SLAND_name in data_SLAND.keys():\n",
    "        \n",
    "        try:\n",
    "            SLAND_val = data_SLAND[SLAND_name].loc[country]\n",
    "            countries_check5.discard(country)\n",
    "        except:\n",
    "            SLAND_val = pd.Series([np.nan] * len(models_SLAND), index=models_SLAND)\n",
    "\n",
    "        #Collect in data frame\n",
    "        SLAND_coll[SLAND_name] = SLAND_val\n",
    "            \n",
    "    #Extract ELUC for BLUE\n",
    "    ELUC_BLUE_2021_val  = data_ELUC_BLUE_2021.loc[country].item()\n",
    "    \n",
    "    #Add values for Serbia and Montenegro for NGHGI\n",
    "    if country=='SCG':\n",
    "        NGHGI_val = data_NGHGI.loc['SRB'].item() + data_NGHGI.loc['MNE'].item()\n",
    "        \n",
    "    #Add values for China, Hong Kong, and Taiwan for BLUE ELUC\n",
    "    if country=='CHN':\n",
    "        ELUC_BLUE_2021_val  = data_ELUC_BLUE_2021.loc['CHN'].item() + data_ELUC_BLUE_2021.loc['TWN'].item() + data_ELUC_BLUE_2021.loc['HKG'].item()\n",
    "\n",
    "    #Calculate gap between NGHGI and ELUC\n",
    "    GAP_val = NGHGI_val - (ELUC_BLUE_2021_val + ELUC_HN_2021_val)/2\n",
    "    \n",
    "    #Save ELUC and NGHGI data in dataframe\n",
    "    data_collect_ELUC_NGHGI.loc[country, 'NGHGI']           = NGHGI_val\n",
    "    data_collect_ELUC_NGHGI.loc[country, 'ELUC_BLUE_2021']  = ELUC_BLUE_2021_val\n",
    "    data_collect_ELUC_NGHGI.loc[country, 'ELUC_HN_2021']    = ELUC_HN_2021_val\n",
    "    data_collect_ELUC_NGHGI.loc[country, 'ELUC_OSCAR_2021'] = ELUC_OSCAR_2021_val\n",
    "    data_collect_ELUC_NGHGI.loc[country, 'GAP']             = GAP_val\n",
    "    \n",
    "    #Save SLAND data in datafame\n",
    "    for SLAND_name in SLAND_coll.columns:\n",
    "\n",
    "        #Add SLAND of single models to dataframe\n",
    "        for model, value in SLAND_coll[SLAND_name].iteritems():\n",
    "            data_collect_SLAND[SLAND_name].loc[country, model] = value\n",
    "\n",
    "#Sort data and calculate ELUC for EU\n",
    "data_collect_ELUC_NGHGI = data_collect_ELUC_NGHGI.sort_index()\n",
    "data_collect_ELUC_NGHGI.loc['EU27_UK'] = data_collect_ELUC_NGHGI.loc[ctrs_EU].sum(axis=0)\n",
    "\n",
    "#Add REDD+ data for COD to NGHGI\n",
    "data_collect_ELUC_NGHGI.loc['COD_REDD+', 'NGHGI'] = data_NGHGI.loc['COD_REDD+', 'NGHGI']\n",
    "\n",
    "#Save ELUC and NGHGI in file\n",
    "file_name = dir_out + 'Collection_ELUC_NGHGI_' + time_str + outname + '.pickle'\n",
    "data_collect_ELUC_NGHGI.to_pickle(file_name)\n",
    "\n",
    "#Loop over different calculation methods for SLAND\n",
    "for SLAND_name in data_SLAND.keys():\n",
    "    \n",
    "    #Sort data and calculate ELUC for EU\n",
    "    data_SLAND_out = data_collect_SLAND[SLAND_name].sort_index()\n",
    "    data_SLAND_out.loc['EU27_UK'] = data_SLAND_out.loc[ctrs_EU].sum(axis=0)\n",
    "    \n",
    "    #Save SLAND in file\n",
    "    file_name = dir_out + 'Collection_' + SLAND_name + '_' + time_str + '.pickle'\n",
    "    data_SLAND_out.to_pickle(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001d6ed-6ade-48f5-b1f7-acc3e1d332ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clemens Python3.10",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
